---
title: "Identifying Risk Factors and Preferred Hospitals for Hip/Knee Replacements: An Analysis of 2019-2022 Hospital Readmission Reduction Program Data"
subtitle: "Team Iota: Preprocessing and Inital Model Report"
author: "Week Five Team Lead: Scott Eugley |  Week Five Recorder/Spokesperson: Adeline Casali"
date: "2024-07-31"
output:
  html_document:
    toc: true
    toc_float: true
    theme: flatly
    fig_crop: no
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      cache = FALSE,
                      cache.comments = TRUE,
                      size = 13)
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# clean, set up, and load
pacman::p_unload(pacman::p_loaded(), character.only = TRUE)
rm(list = ls(all = TRUE))

pacman::p_load(tidyverse, 
               ggplot2, 
               kableExtra, 
               lubridate, 
               caret,
               janitor,
               naniar, 
               maps, 
               psych, 
               reshape2, 
               corrplot,
               VIM,
               glmnet,
               cluster,
               factoextra,
               dendextend,
               randomForest,
               caret, 
               lmtest) 

load("HipKneeClean.Rdata")
load("HipKneeTrain.Rdata")
load("HipKneeTest.Rdata")
```

[GitHub Repository Here](https://github.com/adelinecasali4/hospital-readmission/tree/main)

# Background and Question
### Question  
What are the most significant risk factors associated with hospital readmission rate in hip/knee replacement patients?  

### Hypothesis  
Hospitals with better Hospital Consumer Assessment of Healthcare Providers and Systems (HCAHPS) scores will have lower readmission rates for hip/knee replacements because higher patient satisfaction often correlates with better overall care quality and patient outcomes, including reduced complications and better post-discharge support (Edwards et al., 2015).  

### Prediction  
It is anticipated that patient satisfaction, clinical treatment quality, and operational efficiency will be the most important risk factor categories associated with hospital readmission rates among patients who have had hip or knee replacement surgery. The most important variables influencing readmission rates for patients after hip or knee replacement surgery will most likely be a combination of high HCAHPS scores and reduced rates of clinical complications.  

# Methods
Our preprocessing and feature engineering approach was designed to address the complexities highlighted during exploratory data analysis (EDA). The initial plan involved several key steps:

Preprocessing: We focused on handling missing values, encoding categorical variables, and reducing collinearity. The preprocessing steps included dummy encoding of ordinal data, mapping categorical states to numeric codes, and removing variables with high missingness or redundancy. This approach aimed to ensure that the dataset was clean and suitable for further analysis. We specifically addressed the high number of missing values and collinearity issues as identified in our EDA.

Feature Engineering: We engineered features to consolidate related data and reduce dimensionality. For instance, we created a composite variable for overall mortality scores and removed redundant or highly correlated variables. This strategy aimed to simplify the feature set while retaining critical information, thus enhancing model performance and interpretability.

Initial Model Selection: Based on our EDA findings, we planned to explore multiple methods of unsupervised learning and employ a random forest model. Unsupervised methods, such as KNN for segmentation analysis, were chosen to identify clusters and uncover underlying patterns in the data. The random forest model was selected as an initial supervised learning approach due to its robustness in handling diverse data types and managing feature importance.

## Preprocessing and Feature Selection
To ensure the dataset's suitability for analysis, several preprocessing steps were employed. First, categorical variables were identified, and appropriate encoding methods were applied. The EDV column, which contains ordinal data, was dummy encoded based on predefined levels, transforming it into a numeric format that reflects its ordinal nature. This approach preserves the inherent order of the data while making it suitable for statistical modeling. Additionally, categorical states were encoded using a numeric mapping to eliminate potential ordinal relationships and standardize the representation of states. This choice was made to facilitate model compatibility and avoid any unintended ordinal implications in the analysis.

Unnecessary or highly correlated variables were then removed to streamline the dataset. Variables with significant missingness or redundancy, such as certain patient survey ratings and summary statistics, were excluded. The decision to remove these variables was guided by their high correlation with other variables, high missingness, or redundancy with already included metrics. For instance, combining various patient survey metrics into a single comprehensive score helped reduce collinearity and simplify the feature set. See table 1 for a list of all variables that were removed and justification for doing so. 

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# Create a data frame with the variable names and justifications
removed_vars <- data.frame(
  Variable = c("OP_18c", "OP_22", "ED_2_Strata_1", "OP_23", "VTE_2", 
               "STK_02", "STK_05", "STK_06", "HcahpsLinearMeanValue_H_RECMND_LINEAR_SCORE", 
               "ExcessReadmissionRatio_HIP-KNEE", "ExpectedReadmissionRate_HIP-KNEE", 
               "NumberOfReadmissions_HIP-KNEE", "Sepsis Variables", "Score_PSI_90",
               "Patient Survey Data"),
  Justification = c("Removed due to high correlation and low relevance.",
                     "Removed due to high correlation and low relevance.",
                     "Removed due to high percentage of missingness.",
                     "Removed due to high percentage of missingness.",
                     "Removed due to high percentage of missingness.",
                     "Removed as stroke data is not relevant to Hip/Knee Surgery.",
                     "Removed as stroke data is not relevant to Hip/Knee Surgery.",
                     "Removed as stroke data is not relevant to Hip/Knee Surgery.",
                     "Removed due to strong correlation with overall hospital rating.",
                     "Removed due to high correlation with target variable.",
                     "Removed due to high correlation with target variable.",
                     "Removed as it is influenced by hospital size, which is not available.",
                     "Removed due to unclear definition in dataset dictionary.",
                     "Removed because it is a summary of other PSI variables, making it redundant.",
                     "Removed due to collinearity and redundancy with other patient survey metrics.")
)

# Print the table
removed_vars %>%
  kable(caption = "Table 1: Justifications for Removal of Variables") %>%
  kable_styling(bootstrap_options = c("hover", "striped", "responsive"))
```

Feature engineering focused on creating meaningful variables from existing data and removing irrelevant or redundant features. A notable example is the creation of the Score_Ovr_MORT variable, which aggregates multiple mortality-related scores into a single measure. This new feature consolidates related variables, reducing dimensionality while preserving critical information on mortality rates.

## Initial Model
For our initial model, we chose the Random Forest algorithm due to its robustness and ability to handle a large number of input variables without overfitting. Random Forests are ensemble learning methods that construct multiple decision trees during training and output the mode of the classes (classification) or mean prediction (regression) of the individual trees. This approach helps in managing the complexities and interactions between numerous features in our dataset. We used a grid search with 7-fold cross-validation to tune the mtry parameter, which determines the number of variables considered at each split in the trees.

# Results
## Preprocessing and Feature Engineering
First, categorical variables were appropriately encoded, and redundant variables were removed, as described in the previous section. Collinearity was greatly reduced, as evident by the heat maps in Figure 1 and Figure 2. Additionally, all rows with NA values for the target variables were removed. We also decided to remove the one facility that had an NA value, which happened to be the same observation with a missing state value. Variables with less than 5% missing data were imputed by the median, as this has a small impact on the variation of the predictors. Any variables with greater than 5% missing values were imputed using kNN to allow for more accurate imputation and mitigate reduction in variation. All steps were repeated on the test dataset, which is the most recent snapshot of the data from April 24, 2024. Finally, descriptive statistics were computed for all variables (Table 2, Figure 3). 

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.width=14, fig.height=12}
# Compute correlation matrix
cor_matrix <- cor(HipKneeClean %>% select_if(is.numeric), use = "pairwise.complete.obs")

# Melt the correlation matrix into a long format
cor_melted <- melt(cor_matrix)

# Plot heatmap
ggplot(cor_melted, aes(x = Var1, y = Var2, fill = value)) +
  geom_tile() +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                       midpoint = 0, limit = c(-1, 1), name = "Correlation") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(title = "Figure 1. Correlation Heatmap of Numeric Variables Before Preprocessing")
```

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.width=14, fig.height=12}
# Compute correlation matrix
cor_matrix <- cor(HipKneeTrain %>% select_if(is.numeric), use = "pairwise.complete.obs")

# Melt the correlation matrix into a long format
cor_melted <- melt(cor_matrix)

# Plot heatmap
ggplot(cor_melted, aes(x = Var1, y = Var2, fill = value)) +
  geom_tile() +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                       midpoint = 0, limit = c(-1, 1), name = "Correlation") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(title = "Figure 2. Correlation Heatmap of Numeric Variables After Preprocessing")
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# Create a summary table of descriptive statistics
descr_stats <- describe(HipKneeTrain)
# Remove the rows with Facility ID, State and State code, and facility name
descr_stats <- descr_stats %>% filter(vars != c(1, 23, 24, 26))
# Remove columns 1, 2, 5, and 6
descr_stats <- descr_stats[, -c(1, 2, 5, 6)]

# Create a table with kable
kable(descr_stats, format = "html", caption = "Table 2. Descriptive Statistics for All Numeric Variables in Final Dataset") %>%
  kable_styling(
    bootstrap_options = c("hover", "striped", "responsive")
  ) %>%
  column_spec(1, bold = TRUE) %>%
  column_spec(2, width = "5em") %>%
  row_spec(0, bold = TRUE, background = "#f2f2f2")

# Select numeric columns
numeric_columns <- HipKneeTrain %>% select_if(is.numeric)

# Melt the data for easier plotting with ggplot2
numeric_melted <- melt(numeric_columns)

# Create histograms
ggplot(numeric_melted, aes(x = value)) +
  geom_histogram(bins = 30, fill = "blue", color = "black") +
  facet_wrap(~variable, scales = "free_x") +
  theme_minimal() +
  labs(title = "Figure 3. Histograms of Numeric Variables", x = "Value", y = "Frequency")
```


## Segmentation Analysis
For unsupervised machine learning, we employed both k-means clustering and hierarchical clustering to explore the underlying structure of the dataset. For k-means clustering, we first standardized the numeric features and used the elbow method to determine the optimal number of clusters, which was found to be three. The k-means algorithm was then applied, and cluster characteristics were analyzed by computing the mean of numeric features within each cluster. Visualizations of feature distributions across clusters and the overall cluster structure were created to gain insights into the clustering results (Figure 4).

Hierarchical clustering was also performed to validate the k-means results. We computed a distance matrix and applied Ward’s method to obtain cluster solutions. An analysis of within-cluster sum of squares (WCSS) for different cluster counts was conducted to determine the optimal number of clusters, which again suggested three clusters. The hierarchical clustering results were compared with those from k-means by visualizing clusters in the PCA-reduced feature space and analyzing cluster characteristics (Figure 5). Both clustering methods revealed distinct patterns, but the preliminary findings suggest that the clusters may not be highly meaningful due to potential issues with the data's inherent structure. Overall, the preliminary clustering analysis indicates that while the k-means and hierarchical methods can segment the data, the results may not be sufficiently informative or actionable at this stage.

```{r, include=FALSE}
# Select numeric columns for clustering
numeric_columns <- HipKneeTrain %>% select_if(is.numeric)

# Standardize features
X_scaled <- scale(numeric_columns)

# Determine optimal number of clusters using elbow plot
set.seed(123)
elbow_plot <- fviz_nbclust(X_scaled, kmeans, method = "wss", k.max = 10) +
  labs(title = "Elbow Plot for Optimal k")

print(elbow_plot)

# Optimal K = 3
optimal_k <- 3
kmeans_result <- kmeans(X_scaled, centers = optimal_k, nstart = 25)

# Create a new df for K-Means Clustering results
HipKneeTrain_K_Means <- HipKneeTrain %>%
  mutate(Cluster = as.factor(kmeans_result$cluster))
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# k-means cluster plot
cluster_plot <- fviz_cluster(kmeans_result, data = X_scaled,
                             ellipse.type = "convex",
                             palette = "jco",
                             ggtheme = theme_minimal()) +
  labs(title = "Figure 7. K-Means Clustering Results")

print(cluster_plot)
```


```{r, include=FALSE}
# Perform PCA
pca_result <- prcomp(X_scaled, center = TRUE, scale. = TRUE)

# Visualize variance
fviz_eig(pca_result, addlabels = TRUE)

# Factor map
fviz_pca_var(pca_result, col.var = "contrib",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE)

# PC scores, three components
pca_scores <- as.data.frame(pca_result$x[, 1:3])

# Store PCA results in a new dataframe
HipKneeTrain_PCA <- HipKneeTrain %>%
  select_if(is.numeric) %>%
  bind_cols(pca_scores)

# Hierarchical Clustering

# Compute distance matrix
dist_matrix <- dist(X_scaled, method = "euclidean")

# Perform hierarchical clustering
hc_result <- hclust(dist_matrix, method = "ward.D2")

# Compute WCSS for different number of clusters
wcss <- sapply(1:10, function(k) {
  clusters <- cutree(hc_result, k)
  cluster_data <- scale(X_scaled)
  tot.withinss <- sum(sapply(unique(clusters), function(c) {
    sum(dist(cluster_data[clusters == c, , drop = FALSE])^2)
  }))
  return(tot.withinss)
})

# Plot WCSS
plot(1:10, wcss, type = "b", xlab = "Number of Clusters", ylab = "WCSS")

# Create clusters with optimal number of clusters from WCSS plot
k <- 3
hc_clusters <- cutree(hc_result, k = k)

# Store hierarchical clustering results in a new dataframe
HipKneeTrain_HC <- HipKneeTrain %>%
  mutate(HC_Cluster = as.factor(hc_clusters))
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# Plot the clusters
pca_plot_data <- cbind(pca_scores[, 1:3], Cluster = hc_clusters)
fviz_cluster(list(data = pca_plot_data, cluster = hc_clusters),
             ellipse.type = "convex",
             palette = "jco",
             ggtheme = theme_minimal(),
             main = "Figure 8. Hierarchical Clustering Results (PCA)")
```


## Initial Model 
### Algorithm
We used a Random Forest algorithm for our initial model due to its robustness and ability to handle both regression and classification tasks, while effectively managing multicollinearity and providing insights into feature importances. The model was trained using a grid search over different mtry values and 7-fold cross-validation to identify the best performing parameters. The model's performance on the test set was evaluated using RMSE and R-squared metrics. The RMSE on the test set was 0.337, indicating that the model's predictions were fairly accurate. The R-squared value of 0.863 shows that the model explains a significant portion of the variance in the predicted readmission rates.

### Assumptions
Random Forests make minimal assumptions about the underlying data distribution, which makes them versatile. However, they assume that the data is independent and identically distributed, and the model benefits from a large number of features and observations. To validate these assumptions, we conducted residuals analysis, ensuring no patterns indicating violations of independence or homoscedasticity. The Durbin-Watson test was used to check for autocorrelation in the residuals, and residual plots were examined for any non-random patterns. The results showed that the residuals are relatively randomly distributed, with a slight right skew (Figure 6). However, the Q-Q plot indicates that there are more extreme values than should typically be expected in a normal distribution (Figure 7).

```{r, include=FALSE}
# Remove unwanted columns from the dataset
HipKneeTrain_RF <- HipKneeTrain %>%
  select(-State, -FacilityName, -FacilityId)

# Define mtry parameter grid
grid <- expand.grid(
  mtry = c(2, 4, 6, 8)
)

# Define CV
train_control <- trainControl(
  method = "cv",         
  number = 7,           
  verboseIter = TRUE     
)

# Set seed 
set.seed(123)

# Train the Random Forest model with grid search
rf_grid_search <- train(
  PredictedReadmissionRate_HIP_KNEE ~ .,   
  data = HipKneeTrain_RF,                    
  method = "rf",                          
  trControl = train_control,              
  tuneGrid = grid,                       
  importance = TRUE,                     
  ntree = 100                         
)

# Remove columns from the test set to match train set
HipKneeTest_RF <- HipKneeTest %>%
  select(-State, -FacilityName, -FacilityId)

# Make predictions on test set
rf_predictions <- predict(rf_grid_search, newdata = HipKneeTest_RF)

# Actual values
actual_values <- HipKneeTest$PredictedReadmissionRate_HIP_KNEE

# Calculate RMSE
mse <- mean((rf_predictions - actual_values)^2)
rmse <- sqrt(mse)

# Calculate R-squared
ss_total <- sum((actual_values - mean(actual_values))^2)
ss_residual <- sum((rf_predictions - actual_values)^2)
r_squared <- 1 - (ss_residual / ss_total)

# Calculate residuals
residuals_rf <- actual_values - rf_predictions
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# Histogram of residuals
ggplot(data = NULL, aes(x = residuals_rf)) +
  geom_histogram(binwidth = 0.1, fill = "blue", alpha = 0.7, boundary = 0) +
  labs(title = "Figure 9. Histogram of Residuals",
       x = "Residuals",
       y = "Frequency") +
  theme_minimal()

# QQ plot of residuals
qqnorm(residuals_rf, main = "Figure 10. QQ Plot of Residuals")
qqline(residuals_rf, col = "red")
```


### Overfitting
To address potential overfitting, we employed several strategies:

Validation with Training and Testing Sets: The model was validated using a separate test set, yielding an RMSE of 0.337 and an R-squared of 0.863, indicating good generalization to unseen data.  

Cross-Validation: We used 7-fold cross-validation during the grid search to ensure the model's performance was consistent across different subsets of the data.  

### Feature Importances
The feature importances, sorted by %IncMSE and IncNodePurity, highlight which variables had the most influence on the model's predictions. These insights will guide further feature engineering and model refinement. Below are the top features by %IncMSE and IncNodePurity (Table 3):  

```{r, include=FALSE}
# Best parameters
best_params <- rf_grid_search$bestTune

# Extract feature importances
best_rf_model <- rf_grid_search$finalModel
feature_importances <- importance(best_rf_model)

# Convert feature importances to a df
feature_importances_df <- as.data.frame(feature_importances)
feature_importances_df$Feature <- rownames(feature_importances_df)

# Sort importances by %IncMSE
sorted_by_inc_mse <- feature_importances_df %>%
  arrange(desc(`%IncMSE`))

# Sort importances by IncNodePurity
sorted_by_inc_node_purity <- feature_importances_df %>%
  arrange(desc(IncNodePurity))

# Print importances
cat("Table 3. Feature Importances by %IncMSE:\n")
print(sorted_by_inc_mse)

cat("\n Table 4. Feature Importances by IncNodePurity:\n")
print(sorted_by_inc_node_purity)
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# Combine the two sorted dataframes into one for display
combined_importances <- data.frame(
  Feature = sorted_by_inc_mse$Feature,
  IncMSE = sorted_by_inc_mse$`%IncMSE`,
  Feature2 = sorted_by_inc_node_purity$Feature,
  IncNodePurity = sorted_by_inc_node_purity$IncNodePurity
)

kable(combined_importances, caption = "Table 3. Feature Importances by %IncMSE and IncNodePurity") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))
```


# Discussion and Next Steps
Our preprocessing and feature engineering strategy focused on addressing the data complexities identified during exploratory data analysis (EDA). We handled missing values through imputation and removed variables with high collinearity or redundancy to ensure a clean dataset suitable for modeling. Key preprocessing steps included dummy encoding of ordinal data, standardizing categorical states, and consolidating features to reduce dimensionality. This streamlined approach preserved critical information while simplifying the dataset, enhancing both model performance and interpretability.

For the initial model, we selected the Random Forest algorithm due to its strength in managing diverse data types and its ability to handle multicollinearity effectively. We used a grid search with 7-fold cross-validation to fine-tune the model parameters, achieving an RMSE of 0.337 and an R-squared of 0.863 on the test set, indicating strong predictive performance. We validated model assumptions by analyzing residuals for patterns of autocorrelation and homoscedasticity. Feature importances were evaluated to refine our feature set, guiding further model enhancement. The preprocessing, feature selection, and initial modeling efforts collectively aimed to build a robust predictive model with high generalizability.

Next, we will determine a threshold to categorize hospitals as "preferred" vs "non-preferred" based on the target variable, predicted readmission rate. We will then leverage L1 and L2 regularization via an Elastic Net model to determine significant risk factors. After using Elastic Net and Random Forest to find significant risk factors, these risk factors will be utilized in a neural network model and used to classify hospitals as either “preferred” or “non-preferred”. Classification ability of the neural network model will then be compared with the classification ability of the Random Forest model and Elastic Net model. All of these models will require extensive hyperparameter tuning, particularly the neural network model. 

# Appendix 1: Data Dictionary
```{r, echo=FALSE, message=FALSE, warning=FALSE}
# Define the data dictionary
data_dictionary <- data.frame(
  Measure_ID = c("FacilityId*", "FacilityName", "State", "ExcessReadmissionRatio_HIP-KNEE", 
                 "PredictedReadmissionRate_HIP_KNEE*", "ExpectedReadmissionRate_HIP-KNEE", 
                 "NumberOfReadmissions_HIP-KNEE", "H_HSP_RATING_LINEAR_SCORE*", 
                 "H_RECMND_LINEAR_SCORE", "EDV*", "ED_2", "IMM_3*", "HCP_COVID_19*", 
                 "OP_18b*", "OP_18c", "OP_22", "OP_23", "OP_29*", "SAFE_USE_OF_OPIOIDS*", 
                 "SEP_1", "SEP_SH_3HR", "SEP_SH_6HR", "SEV_SEP_3HR", "SEV_SEP_6HR", 
                 "STK_02", "STK_05", "STK_06", "VTE_1*", "VTE_2", "Score_COMP_HIP_KNEE*", 
                 "Score_MORT_30_AMI", "Score_MORT_30_COPD", "Score_MORT_30_HF", 
                 "Score_MORT_30_PN", "Score_MORT_30_STK", "Score_Ovr_MORT*", 
                 "Score_PSI_03*", "Score_PSI_04*", "Score_PSI_06*", "Score_PSI_08*", 
                 "Score_PSI_09*", "Score_PSI_10*", "Score_PSI_11*", "Score_PSI_12*", 
                 "Score_PSI_13*", "Score_PSI_14*", "Score_PSI_15*", "Score_PSI_90", 
                 "Payment_PAYM_90_HIP_KNEE*"),
  Description = c("Unique facility identifier.", "Name of the facility.", "State where the facility is located.", 
                  "The ratio of the predicted readmission rate to the expected readmission rate, based on an average hospital with similar patients. Performance is compared against a ratio of one, such that below one is better and above one is worse in terms of readmission rates.", 
                  "The number of readmissions within 30 days predicted based on the hospital’s performance with its observed case mix. The predicted number of readmissions is estimated using a hospital-specific intercept, and is intended to reflect the annual expected performance of the hospital given its historical case and patient mix and performance.", 
                  "The expected number of readmissions in each hospital is estimated using its patient mix and an average hospital-specific intercept. It is thus indirectly standardized to other hospitals with similar case and patient mixes.", 
                  "Crude number of readmissions in each hospital within 30 days.", 
                  "Overall hospital rating - linear mean score. Employs all survey response items in each HCAHPS measure and are converted and combined into a 0-100 linear-scaled measure score.", 
                  "Recommend hospital - linear mean score. From question: Would you recommend this hospital to your friends and family?", 
                  "Emergency department volume. Number based on the volume of patients submitted by a hospital used for the measure OP-22: Left without Being Seen.", 
                  "Average (median) admit decision time to time of departure from the emergency department for emergency department patients admitted to inpatient status.", 
                  "Healthcare workers given influenza vaccination.", 
                  "COVID-19 vaccination coverage among healthcare providers.", 
                  "Average (median) time patients spent in the emergency department before leaving from the visit.", 
                  "Average time patients spent in the emergency department before being sent home (Median Time from ED Arrival to ED Departure for Discharged ED Patients – Psychiatric/Mental Health Patients).", 
                  "Percentage of patients who left the emergency department before being seen.", 
                  "Percentage of patients who came to the emergency department with stroke symptoms who received brain scan results within 45 minutes of arrival.", 
                  "Percentage of patients receiving appropriate recommendation for follow-up screening colonoscopy.", 
                  "Percentage of patients who were prescribed 2 or more opioids or an opioid and benzodiazepine concurrently at discharge.", 
                  "Severe sepsis and septic shock.", 
                  "Septic shock 3 hour.", 
                  "Septic shock 6 hour.", 
                  "Severe sepsis 3 hour.", 
                  "Severe sepsis 6 hour.", 
                  "Percentage of ischemic stroke patients prescribed or continuing to take antithrombotic therapy at hospital discharge.", 
                  "Percentage of ischemic stroke patients administered antithrombotic therapy by the end of hospital day 2.", 
                  "Percentage of ischemic stroke patients who are prescribed or continuing to take statin medication at hospital discharge.", 
                  "Percentage of patients that received VTE prophylaxis after hospital admission or surgery.", 
                  "Percentage of patients that received VTE prophylaxis after being admitted to the intensive care unit (ICU).", 
                  "Rate of complications for hip/knee replacement patients.", 
                  "Death rate for heart attack patients.", 
                  "Death rate for chronic obstructive pulmonary disease (COPD) patients.", 
                  "Death rate for heart failure patients.", 
                  "Death rate for pneumonia patients.", 
                  "Death rate for stroke patients.", 
                  "Summary measure (row-wise mean) of Score_MORT_30_AMI, Score_MORT_30_COPD, Score_MORT_30_HF, Score_MORT_30_PN, and Score_MORT_30_STK.", 
                  "Rate of pressure sores.", 
                  "Deaths among patients with serious treatable complications after surgery.", 
                  "Collapsed lung due to medical treatment.", 
                  "Broken hip from a fall after surgery.", 
                  "Postoperative hemorrhage or hematoma rate.", 
                  "Kidney and diabetic complications after surgery.", 
                  "Respiratory failure after surgery.", 
                  "Serious blood clots after surgery.", 
                  "Blood stream infection after surgery.", 
                  "A wound that splits open after surgery on the abdomen or pelvis.", 
                  "Accidental cuts and tears from medical treatment.", 
                  "Serious complications (this is a composite or summary measure).", 
                  "Payment for hip/knee replacement - estimates of payments associated with a 90-day episode of care for hip/knee replacement.")
)

# Create the table
kable(data_dictionary, caption = "Data Dictionary<br><i>* indicates measure utilized in final dataset</i>") %>%
  kable_styling(full_width = F, position = "center", bootstrap_options = c("striped", "hover", "condensed"))
```

# Appendix 2: Preprocessing and Feature Engineering Code

## Variable Encoding (SE)

#### Identify Categorical Variables
```{r}
# Create function to find categorical variables
is_categorical <- function(x) is.factor(x) | is.character(x)

# Apply function to all variables in the dataset
categorical_vars <- sapply(HipKneeClean, is_categorical)

# Print the names of all categorical variables
categorical <- names(HipKneeClean)[categorical_vars]
categorical
```

#### Dummy encode the EDV column 
```{r}
# Define the encoding mapping (ignore NAs for now)
encoding_map <- c(
  'low' = 1,
  'medium' = 2,
  'high' = 3,
  'very high' = 4
)
# Dummy encoding used due to ordinal nature of this data

# Create a copy of HipKneeClean and name it HipKneeTrain to separate cleaned dataset and the training dataset
HipKneeTrain <- HipKneeClean %>%
  mutate(EDV = recode(EDV, !!!encoding_map))

# Print first 20 rows of EDV column in HipKneeClean and HipKneeTrain to ensure proper encoding
cat("HipKneeClean")
print(head(HipKneeClean$EDV, 20))

cat("HipKneeTrain")
print(head(HipKneeTrain$EDV, 20))
```

#### Encode each state in alphabetical order
```{r}
# Manually map out each state with their respective code in alphabetical order with a preceding 0 to make data non-ordinal
state_mapping <- c(
  "AL" = "001",
  "AK" = "002",
  "AZ" = "003",
  "AR" = "004",
  "CA" = "005",
  "CO" = "006",
  "CT" = "007",
  "DE" = "008",
  "FL" = "009",
  "GA" = "010",
  "HI" = "011",
  "ID" = "012",
  "IL" = "013",
  "IN" = "014",
  "IA" = "015",
  "KS" = "016",
  "KY" = "017",
  "LA" = "018",
  "ME" = "019",
  "MD" = "020",
  "MA" = "021",
  "MI" = "022",
  "MN" = "023",
  "MS" = "024",
  "MO" = "025",
  "MT" = "026",
  "NE" = "027",
  "NV" = "028",
  "NH" = "029",
  "NJ" = "030",
  "NM" = "031",
  "NY" = "032",
  "NC" = "033",
  "ND" = "034",
  "OH" = "035",
  "OK" = "036",
  "OR" = "037",
  "PA" = "038",
  "RI" = "039",
  "SC" = "040",
  "SD" = "041",
  "TN" = "042",
  "TX" = "043",
  "UT" = "044",
  "VT" = "045",
  "VA" = "046",
  "WA" = "047",
  "WV" = "048",
  "WI" = "049",
  "WY" = "050"
)

# Create new "StateCode" column with the encoded values
HipKneeTrain <- HipKneeTrain %>%
  mutate(StateCode = state_mapping[State])

# Print 100 rows of the "State" and "StateCode" columns to ensure accuracy
print("State and StateCode Columns")
print(head(HipKneeTrain[c("State", "StateCode")], 100))

# Print all unique values in "StateCode" column to ensure accuracy
print("Unique StateCode Values")
print(unique(HipKneeTrain$StateCode))
```

## Collinearity and Feature Removal (SE)

#### Remove correlated and unnecessary variables 
```{r}
# Specify columns to remove
columns_to_remove <- c(
  "ED_2_Strata_1",
  "OP_23",
  "VTE_2",
  "OP_18c",
  "OP_22",
  "STK_02",
  "STK_05",
  "STK_06",
  "HcahpsLinearMeanValue_H_RECMND_LINEAR_SCORE",
  "NumberOfReadmissions_HIP-KNEE",
  "ExcessReadmissionRatio_HIP-KNEE",
  "ExpectedReadmissionRate_HIP-KNEE",
  "SEP_1",
  "SEV_SEP_6HR",
  "SEV_SEP_3HR",
  "SEP_SH_6HR",
  "SEP_SH_3HR",
  "Score_PSI_90",
  "PatientSurveyStarRating_H_COMP_1_STAR_RATING",    
  "PatientSurveyStarRating_H_COMP_2_STAR_RATING",    
  "PatientSurveyStarRating_H_COMP_3_STAR_RATING",    
  "PatientSurveyStarRating_H_COMP_5_STAR_RATING",    
  "PatientSurveyStarRating_H_COMP_6_STAR_RATING",    
  "PatientSurveyStarRating_H_COMP_7_STAR_RATING",    
  "PatientSurveyStarRating_H_CLEAN_STAR_RATING",     
  "PatientSurveyStarRating_H_QUIET_STAR_RATING",     
  "PatientSurveyStarRating_H_HSP_RATING_STAR_RATING",
  "PatientSurveyStarRating_H_RECMND_STAR_RATING",    
  "PatientSurveyStarRating_H_STAR_RATING",
  "HcahpsLinearMeanValue_H_COMP_1_LINEAR_SCORE",    
  "HcahpsLinearMeanValue_H_COMP_2_LINEAR_SCORE",    
  "HcahpsLinearMeanValue_H_COMP_3_LINEAR_SCORE",    
  "HcahpsLinearMeanValue_H_COMP_5_LINEAR_SCORE",    
  "HcahpsLinearMeanValue_H_COMP_6_LINEAR_SCORE",    
  "HcahpsLinearMeanValue_H_COMP_7_LINEAR_SCORE",    
  "HcahpsLinearMeanValue_H_CLEAN_LINEAR_SCORE",     
  "HcahpsLinearMeanValue_H_QUIET_LINEAR_SCORE"
)

# Remove specified columns
HipKneeTrain <- HipKneeTrain %>% select(-all_of(columns_to_remove))
```

```{r}
# Print column names to verify
print("Remaining columns:")
print(colnames(HipKneeTrain))
```
> "OP_18c" and "OP_22" removed due to being highly correlated and low relevance.
> "ED_2_Strata_1", "OP_23", and "VTE_2" removed due to high percentage of missingness. 
> "STK_02", "STK_05", and "STK_06" variables removed as we do not see stroke data as being relevant towards Hip/Knee Surgery.
> "HcahpsLinearMeanValue_H_RECMND_LINEAR_ SCORE" removed as it is strongly correlated with overall hospital rating.
> "ExcessReadmissionRatio_HIP-KNEE", and "ExpectedReadmissionRate_HIP-KNEE" removed due to being highly correlated with the target variable. "NumberOfReadmissions_HIP-KNEE" removed as this would be highly influenced by hospital size and we have no data on hospital sizes.
> Sepsis variables removed due to unclear definition in the dataset's dictionary of what the values represent.
> Score_PSI_90 variable removed because it's a summary of the other PSI variables. We chose to include all the individual PSI variables, which makes the summary variable redundant. 
> We chose to remove a lot of the patient survey data due to collinearity and redundancy. The average star rating data is redundant with the linear mean score data. We decided to keep the overall hospital rating linear mean score, and the hospital recommendation linear mean score columns. We felt that these variables summarized the other, more granular, metrics. For example COMP-1 is nurse responsiveness and COMP-2 is doctor responsiveness, COMP-3 is staff responsiveness. It makes sense that a lot of these were collinear. We had considered engineering the comp features (1-7) together into a single patient experience variable, however, this was collinear with overall hospital rating and recommendation. We also chose to go with the linear mean score overall hospital rating and recommendation score, because the dataset essentially already scaled these variables for us by performing a linear transformation. 
> It always seems a little scary removing entire chunks of variables, as we wouldn't want to miss any significant relationships between the variables. Do you think this is a wise decision? Are there any other ideas you could think of to engineer variables in a way to keep more of them? 

#### Reassess collinearity with heatmap and correlation matrix
```{r, fig.width=14, fig.height=15}
# Compute correlation matrix
cor_matrix <- cor(HipKneeTrain %>% select_if(is.numeric), use = "pairwise.complete.obs")

# Melt the correlation matrix into a long format
cor_melted <- melt(cor_matrix)

# Plot heatmap
ggplot(cor_melted, aes(x = Var1, y = Var2, fill = value)) +
  geom_tile() +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                       midpoint = 0, limit = c(-1, 1), name = "Correlation") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(title = "Figure 5. Correlation Heatmap of Numeric Variables")

# Convert correlation matrix to df
cor_table <- as.data.frame(cor_matrix)

# Add variable names as a column
cor_table$Variable <- rownames(cor_table)

# Reorder columns
cor_table <- cor_table %>%
  select(Variable, everything())

# Print table
cor_table %>%
  kable(caption = "Table 8. Correlation Coefficients Table") %>%
  kable_styling(bootstrap_options = c("hover", "striped", "responsive"))
```

## Imputation and Handling of Missing Values (AC)

```{r}
# Change - to _ in HIP-KNEE
colnames(HipKneeTrain) <- gsub("-", "_", colnames(HipKneeTrain))

# Remove all NA values in target variable "PredictedReadmissionRate_HIP_KNEE"
HipKneeTrain <- HipKneeTrain %>% filter(!is.na(PredictedReadmissionRate_HIP_KNEE))

# Remove all NA values in the "State", "StateCode", and "FacilityName" columns
HipKneeTrain <- HipKneeTrain %>% drop_na(State, StateCode, FacilityName)


# Print number of remaining variables and observations
dimensions <- dim(HipKneeTrain)
cat("Number of variables:", dimensions[2], "\n")
cat("Number of observations:", dimensions[1], "\n")
```
> We decided to remove the one facility that had an NA value, which also happened to be the same observation with a missing state value.

```{r}
# Calculate missing values
missing_values_summary <- HipKneeTrain %>%
  summarise(across(everything(), ~ sum(is.na(.)))) %>%
  pivot_longer(cols = everything(), names_to = "Variable", values_to = "Missing_Count") %>%
  mutate(Missing_Percentage = (Missing_Count / nrow(HipKneeTrain)) * 100)

# Print table
missing_values_summary %>%
  kable(caption = "Table 7. Missing Values Summary") %>%
  kable_styling(bootstrap_options = c("hover", "striped", "responsive"))
```
#### Impute variables with low percentage missingness (<5%) by the median for numeric variables and mode for categorical variables
```{r}
# Calculate median for columns with <5% missing values
numeric_vars_low_missing <- c("HcahpsLinearMeanValue_H_HSP_RATING_LINEAR_SCORE", "EDV", "HCP_COVID_19", "IMM_3", "OP_18b", "SAFE_USE_OF_OPIOIDS", "Score_COMP_HIP_KNEE", "Score_PSI_03", "Score_PSI_06", "Score_PSI_08", "Score_PSI_09", "Score_PSI_10", "Score_PSI_11", "Score_PSI_12", "Score_PSI_13", "Score_PSI_14", "Score_PSI_15", "Payment_PAYM_90_HIP_KNEE")

for (var in numeric_vars_low_missing) {
  HipKneeTrain[[var]][is.na(HipKneeTrain[[var]])] <- median(HipKneeTrain[[var]], na.rm = TRUE)
}
```

#### Impute high percentage missingness variables (>5%) using KNN
```{r}
# Select high missingness variables for KNN imputation
vars_for_knn <- c("VTE_1", "Score_MORT_30_AMI", "Score_MORT_30_COPD", "Score_MORT_30_HF", "Score_MORT_30_PN", "Score_MORT_30_STK", "Score_PSI_04", "OP_29")

# Perform KNN imputation
HipKneeTrain_knn <- kNN(HipKneeTrain, variable = vars_for_knn, k = 5)

# Remove columns created by the KNN function
HipKneeTrain_knn <- HipKneeTrain_knn %>% select(-ends_with("_imp"))

# Update HipKneeTrain with imputed values
HipKneeTrain[vars_for_knn] <- HipKneeTrain_knn[vars_for_knn]
```

```{r}
# Calculate missing values
missing_values_summary <- HipKneeTrain %>%
  summarise(across(everything(), ~ sum(is.na(.)))) %>%
  pivot_longer(cols = everything(), names_to = "Variable", values_to = "Missing_Count") %>%
  mutate(Missing_Percentage = (Missing_Count / nrow(HipKneeTrain)) * 100)

# Print table
missing_values_summary %>%
  kable(caption = "Table 7. Missing Values Summary") %>%
  kable_styling(bootstrap_options = c("hover", "striped", "responsive"))
```

## Feature Engineer Mortality Data (AC)
```{r}
# Average death rates amongst mortality variables and create new column "Score_Ovr_MORT"
HipKneeTrain$Score_Ovr_MORT <- rowMeans(HipKneeTrain[, c("Score_MORT_30_AMI", 
                                                         "Score_MORT_30_COPD", 
                                                         "Score_MORT_30_HF", 
                                                         "Score_MORT_30_PN", 
                                                         "Score_MORT_30_STK")], 
                                                          na.rm = TRUE)

# Remove old mortality columns
HipKneeTrain <- HipKneeTrain[, !(names(HipKneeTrain) %in% c("Score_MORT_30_AMI", 
                                                            "Score_MORT_30_COPD",
                                                            "Score_MORT_30_HF", 
                                                            "Score_MORT_30_PN", 
                                                            "Score_MORT_30_STK"))]

```

#### Reassess heatmap with engineered mortality data
```{r, fig.width=14, fig.height=15}
# Compute correlation matrix
cor_matrix <- cor(HipKneeTrain %>% select_if(is.numeric), use = "pairwise.complete.obs")

# Melt the correlation matrix into a long format
cor_melted <- melt(cor_matrix)

# Plot heatmap
ggplot(cor_melted, aes(x = Var1, y = Var2, fill = value)) +
  geom_tile() +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                       midpoint = 0, limit = c(-1, 1), name = "Correlation") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(title = "Figure 5. Correlation Heatmap of Numeric Variables")
```

#### Save the data for future ease of use
```{r}
save(HipKneeTrain, file = "HipKneeTrain.RData")
```

## Preprocessing the test dataset (AC)
We are utilizing the most recent snapshot from 04/24/2024 as our test set. Utilizing this brand new data will help to ensure that our model is generalizable and useful for future analyses. 

### Loading the Data 
```{r, message=FALSE, warning=FALSE}
# Set the directory for the data files
filepath <- "/Users/adelinecasali/Desktop/hospitals_04_2024/" 

# List the files in the directory that have "Hospital.csv"
files <- list.files(path = filepath, pattern = "Hospital.csv")

# Iterate through each file in the list
for(f in 1:length(files)) {
  
# Read the CSV, clean column names to upper camel case, and store in "dat"
    dat <- clean_names(read_csv(paste0(filepath, files[f]),
                                show_col_types = FALSE), 
                       case = "upper_camel")
    
# Remove ".Hospital.csv" part of the file names to create variable name
    filename <- gsub(".Hospital\\.csv", "", files[f])
    
# Assign data to a variable with the above created name
    assign(filename, dat)
}
# Create a df of file names without ".Hospital.csv"
files <- gsub(".Hospital\\.csv", "", files) %>% data.frame()

# Set column name of the df to "File Name"
names(files) <- "File Name"

files %>% 
  kable(
    format = "html",
    caption = "Table 1. List of hospital-level data files.") %>%
    kable_styling(bootstrap_options = c("striped", full_width = F)
  )
```

### Exploring and Preprocessing the FY_2024_Hospital_Readmissions_Reduction_Program dataset (AC)  

#### Viewing and checking for missing values  
```{r}
# Display first 10 rows of FY_2024_Hospital_Readmissions_Reduction_Program 
head(FY_2024_Hospital_Readmissions_Reduction_Program,10)

# Filter dataset to include numeric columns only
num_vars <- FY_2024_Hospital_Readmissions_Reduction_Program %>%
  select_if(is.numeric)

# Check for missing values
miss_vals <- sapply(num_vars, function(x) sum(is.na(x)))
print(miss_vals)
```

#### Replacing values with NA and "Too Few to Report" values with "5"  
```{r}
# Use the function "replace_with_na_all()" to replace aberrant values with NA
FY_2024_Hospital_Readmissions_Reduction_Program <- replace_with_na_all(FY_2024_Hospital_Readmissions_Reduction_Program, condition = ~ .x == "N/A")

# Replace "Too Few to Report" values with "5" in using gsub
FY_2024_Hospital_Readmissions_Reduction_Program$NumberOfReadmissions <- gsub("Too Few to Report", "5", FY_2024_Hospital_Readmissions_Reduction_Program$NumberOfReadmissions)

# Check first 10 rows to confirm that it worked
head(FY_2024_Hospital_Readmissions_Reduction_Program$NumberOfReadmissions, 10)

# NumberOfReadmissions had to be converted to numeric before applying integers
FY_2024_Hospital_Readmissions_Reduction_Program$NumberOfReadmissions <- as.numeric(FY_2024_Hospital_Readmissions_Reduction_Program$NumberOfReadmissions)

# Find all values of "5" in NumberOfReadmissions
fives <- which(FY_2024_Hospital_Readmissions_Reduction_Program$NumberOfReadmissions == 5)

# Replace values of "5" with random integers from 1 - 10
FY_2024_Hospital_Readmissions_Reduction_Program$NumberOfReadmissions[fives] <- sample(1:10, length(fives), replace = TRUE)

# Check the first 20 rows to see if this was applied correctly
head(FY_2024_Hospital_Readmissions_Reduction_Program$NumberOfReadmissions,20)
```

#### Converting columns to numeric  
```{r}
# Selecting the columns to convert
columns_to_convert <- c("NumberOfDischarges", "ExcessReadmissionRatio", "PredictedReadmissionRate", "ExpectedReadmissionRate", "NumberOfReadmissions")

# Use mutate_at to convert the specified columns to numeric
FY_2024_Hospital_Readmissions_Reduction_Program <- FY_2024_Hospital_Readmissions_Reduction_Program %>%
  mutate_at(vars(one_of(columns_to_convert)), as.numeric)

# Print the structure of the dataframe to check the changes
str(FY_2024_Hospital_Readmissions_Reduction_Program)
```

#### Removing excess text from measure names
```{r}
FY_2024_Hospital_Readmissions_Reduction_Program <-  FY_2024_Hospital_Readmissions_Reduction_Program %>%
  mutate(MeasureName = gsub("READM-30-", "", MeasureName)) %>% 
  mutate(MeasureName = gsub("-HRRP", "", MeasureName)) 
```

#### Pivoting the data wider  
```{r}
readmissionsClean <- FY_2024_Hospital_Readmissions_Reduction_Program %>%
  pivot_wider(
    names_from = MeasureName, 
    values_from = c(NumberOfDischarges, ExcessReadmissionRatio, PredictedReadmissionRate, ExpectedReadmissionRate, NumberOfReadmissions), 
    id_cols = c(FacilityName, FacilityId, State, StartDate, EndDate)
  )

# Check the new dataframe
dim(readmissionsClean)
head(readmissionsClean)
```

#### Filtering for only hip/knee conditions
```{r}
readmissionsClean <- readmissionsClean %>%
  select(FacilityName, FacilityId, State, matches("HIP-KNEE$"))
```

### Exploring and Preprocessing the HCAHPS dataset 

#### Viewing and checking for missing values  
```{r}
# Display first 10 rows of HCAHPS 
head(HCAHPS,10)

# Filter dataset to include numeric columns only
num_vars <- HCAHPS %>%
  select_if(is.numeric)

# Check for missing values
miss_vals <- sapply(num_vars, function(x) sum(is.na(x)))
print(miss_vals)
```

#### Removing footnote columns and replacing NA values  
```{r}
# Removing all footnote columns
HCAHPS <- HCAHPS %>%
  select(-ends_with("footnote"))

# Replacing all "Not Applicable" with NA
HCAHPS <- as.data.frame(sapply(HCAHPS, function(x) {
  if (is.character(x)) {
    x[x == "Not Applicable"] <- NA
  }
  return(x)
}))

# Replacing all "Not Available" with NA
HCAHPS <- as.data.frame(sapply(HCAHPS, function(x) {
  if (is.character(x)) {
    x[x == "Not Available"] <- NA
  }
  return(x)
}))
```

#### Pivoting the data wider  
```{r}
HCAHPSClean <- HCAHPS %>%
  pivot_wider(
    names_from = HcahpsMeasureId, 
    values_from = c(PatientSurveyStarRating, HcahpsAnswerPercent, HcahpsLinearMeanValue, SurveyResponseRatePercent), 
    id_cols = c(FacilityName, FacilityId, State)
  )

# Check the new dataframe
dim(HCAHPSClean)
head(HCAHPSClean)
```

### Exploring and Preprocessing the Timely_and_Effective_Care dataset 

#### Viewing and checking for missing values  
```{r}
# Display first 10 rows of Timely_and_Effective_Care
head(Timely_and_Effective_Care,10)

# Filter dataset to include numeric columns only
num_vars <- Timely_and_Effective_Care %>%
  select_if(is.numeric)

# Check for missing values
miss_vals <- sapply(num_vars, function(x) sum(is.na(x)))
print(miss_vals)
```

#### Replacing NA values  
```{r}
# Replacing all "Not Applicable" with NA
Timely_and_Effective_Care <- as.data.frame(sapply(Timely_and_Effective_Care, function(x) {
  if (is.character(x)) {
    x[x == "Not Applicable"] <- NA
  }
  return(x)
}))

# Replacing all "Not Available" with NA
Timely_and_Effective_Care <- as.data.frame(sapply(Timely_and_Effective_Care, function(x) {
  if (is.character(x)) {
    x[x == "Not Available"] <- NA
  }
  return(x)
}))
```

#### Pivoting the data wider  
```{r}
careClean <- Timely_and_Effective_Care %>%
  pivot_wider(
    names_from = MeasureId, 
    values_from = c(Score), 
    id_cols = c(FacilityName, FacilityId, State)
  )

# Check the new dataframe
dim(careClean)
head(careClean)
```

### Exploring and Preprocessing the Complications_and_Deaths dataset

#### Viewing and checking for missing values  
```{r}
# Display first 10 rows of Complications_and_Deaths
head(Complications_and_Deaths,10)

# Filter dataset to include numeric columns only
num_vars <- Complications_and_Deaths %>%
  select_if(is.numeric)

# Check for missing values
miss_vals <- sapply(num_vars, function(x) sum(is.na(x)))
print(miss_vals)
```

#### Replacing NA values  
```{r}
# Replacing all "Not Applicable" with NA
Complications_and_Deaths <- as.data.frame(sapply(Complications_and_Deaths, function(x) {
  if (is.character(x)) {
    x[x == "Not Applicable"] <- NA
  }
  return(x)
}))

# Replacing all "Not Available" with NA
Complications_and_Deaths <- as.data.frame(sapply(Complications_and_Deaths, function(x) {
  if (is.character(x)) {
    x[x == "Not Available"] <- NA
  }
  return(x)
}))
```

#### Pivoting the data wider  
```{r}
deathsClean <- Complications_and_Deaths %>%
  pivot_wider(
    names_from = MeasureId, 
    values_from = c(ComparedToNational, Score), 
    id_cols = c(FacilityName, FacilityId, State)
  )

# Check the new dataframe
dim(deathsClean)
head(deathsClean)
```

### Exploring and Preprocessing the Payment_and_Value_of_Care dataset 

#### Viewing and checking for missing values  
```{r}
# Display first 10 rows of Payment_and_Value_of_Care
head(Payment_and_Value_of_Care,10)

# Filter dataset to include numeric columns only
num_vars <- Payment_and_Value_of_Care %>%
  select_if(is.numeric)

# Check for missing values
miss_vals <- sapply(num_vars, function(x) sum(is.na(x)))
print(miss_vals)
```

#### Replacing NA values  
```{r}
# Replacing all "Not Applicable" with NA
Payment_and_Value_of_Care <- as.data.frame(sapply(Payment_and_Value_of_Care, function(x) {
  if (is.character(x)) {
    x[x == "Not Applicable"] <- NA
  }
  return(x)
}))

# Replacing all "Not Available" with NA
Payment_and_Value_of_Care <- as.data.frame(sapply(Payment_and_Value_of_Care, function(x) {
  if (is.character(x)) {
    x[x == "Not Available"] <- NA
  }
  return(x)
}))
```

#### Pivoting the data wider  
```{r}
paymentClean <- Payment_and_Value_of_Care %>%
  pivot_wider(
    names_from = PaymentMeasureId, 
    values_from = c(PaymentCategory, Payment), 
    id_cols = c(FacilityName, FacilityId, State)
  )

# Check the new dataframe
dim(paymentClean)
head(paymentClean)
```

#### Selecting only Hip-Knee related  
```{r}
paymentClean <- paymentClean %>%
  select(FacilityName, FacilityId, State, matches("HIP_KNEE$"))
```

### Joining and cleaning the datasets  

#### Joining the datasets based on FacilityId
```{r}
HipKneeCleanTest <- readmissionsClean %>%
  full_join(HCAHPSClean, by = "FacilityId") %>%
  full_join(careClean, by = "FacilityId") %>%
  full_join(deathsClean, by = "FacilityId") %>%
  full_join(paymentClean, by = "FacilityId")

head(HipKneeCleanTest)
```

#### Removing redundant columns  
```{r}
# Removing duplicate columns
HipKneeCleanTest <- HipKneeCleanTest %>%
  select(-matches("\\.(x|y|z|w|v)$"))
```

#### Checking for NA Values  
```{r, results='hide'}
# Checking the dimensions
dim(HipKneeCleanTest)

# Count NA values in each column
na_counts <- sapply(HipKneeCleanTest, function(x) sum(is.na(x)))

# View the NA counts
print(na_counts)
```

#### Removing columns with more than 80% NA values
```{r, results='hide'}
# Calculate the percentage of NA values for each column
na_percentage <- sapply(HipKneeCleanTest, function(x) mean(is.na(x)))

# Remove columns where more than 80% of the values are NA
HipKneeCleanTest <- HipKneeCleanTest[, na_percentage <= 0.8]

# Count NA values in each column
na_counts <- sapply(HipKneeCleanTest, function(x) sum(is.na(x)))

# View the NA counts
print(na_counts)

# Check the dimensions
dim(HipKneeCleanTest)
```

#### Removing answer percent and survey response percent columns
```{r}
# Remove columns containing 'AnswerPercent' or 'SurveyResponseRate'
HipKneeCleanTest <- HipKneeCleanTest %>%
  select(-matches("AnswerPercent|SurveyResponseRate"))

# Check the dimensions
dim(HipKneeCleanTest)
```

#### Removing compared to national columns  
```{r}
# Remove columns containing 'ComparedToNational' and 'PaymentCategory'
HipKneeCleanTest <- HipKneeCleanTest %>%
  select(-matches("ComparedToNational|PaymentCategory"))

# Check the dimensions
dim(HipKneeCleanTest)
```

#### Checking data structure
```{r}
str(HipKneeCleanTest)

# Convert columns to numeric
HipKneeCleanTest <- HipKneeCleanTest %>%
  mutate_at(vars(starts_with("PatientSurveyStarRating_"), 
                 starts_with("HcahpsLinearMeanValue_"), 
                 starts_with("Score_"),
                 starts_with("ED_"),
                 starts_with("IMM_"),
                 starts_with("OP_"),
                 starts_with("SEP_"),
                 starts_with("SEV_"),
                 starts_with("STK_"),
                 starts_with("VTE_"),
                 starts_with("SAFE_"),
                 starts_with("HCP_")),
            ~ as.numeric(as.character(.)))

# View the structure
str(HipKneeCleanTest)
```

#### Fixing the payment column
```{r}
# Remove $ and , and convert to numeric
HipKneeCleanTest <- HipKneeCleanTest %>%
  mutate_at(vars(starts_with("Payment_")), 
            ~ as.numeric(gsub("[\\$,]", "", .)))

# Checking the structure
str(HipKneeCleanTest)
```

### Encoding categorical variables

#### Identify Categorical Variables
```{r}
# Create function to find categorical variables
is_categorical <- function(x) is.factor(x) | is.character(x)

# Apply function to all variables in the dataset
categorical_vars <- sapply(HipKneeClean, is_categorical)

# Print the names of all categorical variables
categorical <- names(HipKneeClean)[categorical_vars]
categorical
```

#### Dummy encode the EDV column 
```{r}
# Define the encoding mapping (ignore NAs for now)
encoding_map <- c(
  'low' = 1,
  'medium' = 2,
  'high' = 3,
  'very high' = 4
)
# Dummy encoding used due to ordinal nature of this data

# Create a copy of HipKneeCleanTest and name it HipKneeTest to separate cleaned dataset and the test dataset
HipKneeTest <- HipKneeCleanTest %>%
  mutate(EDV = recode(EDV, !!!encoding_map))

# Print first 20 rows of EDV column in HipKneeClean and HipKneeTrain to ensure proper encoding
cat("HipKneeCleanTest")
print(head(HipKneeCleanTest$EDV, 20))

cat("HipKneeTest")
print(head(HipKneeTest$EDV, 20))
```

#### Encode each state in alphabetical order
```{r}
# Manually map out each state with their respective code in alphabetical order with a preceding 0 to make data non-ordinal
state_mapping <- c(
  "AL" = "001",
  "AK" = "002",
  "AZ" = "003",
  "AR" = "004",
  "CA" = "005",
  "CO" = "006",
  "CT" = "007",
  "DE" = "008",
  "FL" = "009",
  "GA" = "010",
  "HI" = "011",
  "ID" = "012",
  "IL" = "013",
  "IN" = "014",
  "IA" = "015",
  "KS" = "016",
  "KY" = "017",
  "LA" = "018",
  "ME" = "019",
  "MD" = "020",
  "MA" = "021",
  "MI" = "022",
  "MN" = "023",
  "MS" = "024",
  "MO" = "025",
  "MT" = "026",
  "NE" = "027",
  "NV" = "028",
  "NH" = "029",
  "NJ" = "030",
  "NM" = "031",
  "NY" = "032",
  "NC" = "033",
  "ND" = "034",
  "OH" = "035",
  "OK" = "036",
  "OR" = "037",
  "PA" = "038",
  "RI" = "039",
  "SC" = "040",
  "SD" = "041",
  "TN" = "042",
  "TX" = "043",
  "UT" = "044",
  "VT" = "045",
  "VA" = "046",
  "WA" = "047",
  "WV" = "048",
  "WI" = "049",
  "WY" = "050"
)

# Create new "StateCode" column with the encoded values
HipKneeTest <- HipKneeTest %>%
  mutate(StateCode = state_mapping[State])

# Print 100 rows of the "State" and "StateCode" columns to ensure accuracy
print("State and StateCode Columns")
print(head(HipKneeTest[c("State", "StateCode")], 100))

# Print all unique values in "StateCode" column to ensure accuracy
print("Unique StateCode Values")
print(unique(HipKneeTest$StateCode))
```

### Collinearity and Feature Removal

#### Remove correlated and unnecessary variables 
```{r}
# Specify columns to remove
columns_to_remove <- c(
  "ED_2_Strata_1",
  "OP_23",
  "VTE_2",
  "OP_18c",
  "OP_22",
  "STK_02",
  "STK_05",
  "STK_06",
  "HcahpsLinearMeanValue_H_RECMND_LINEAR_SCORE",
  "NumberOfReadmissions_HIP-KNEE",
  "ExcessReadmissionRatio_HIP-KNEE",
  "ExpectedReadmissionRate_HIP-KNEE",
  "SEP_1",
  "SEV_SEP_6HR",
  "SEV_SEP_3HR",
  "SEP_SH_6HR",
  "SEP_SH_3HR",
  "Score_PSI_90",
  "PatientSurveyStarRating_H_COMP_1_STAR_RATING",    
  "PatientSurveyStarRating_H_COMP_2_STAR_RATING",    
  "PatientSurveyStarRating_H_COMP_3_STAR_RATING",    
  "PatientSurveyStarRating_H_COMP_5_STAR_RATING",    
  "PatientSurveyStarRating_H_COMP_6_STAR_RATING",    
  "PatientSurveyStarRating_H_COMP_7_STAR_RATING",    
  "PatientSurveyStarRating_H_CLEAN_STAR_RATING",     
  "PatientSurveyStarRating_H_QUIET_STAR_RATING",     
  "PatientSurveyStarRating_H_HSP_RATING_STAR_RATING",
  "PatientSurveyStarRating_H_RECMND_STAR_RATING",    
  "PatientSurveyStarRating_H_STAR_RATING",
  "HcahpsLinearMeanValue_H_COMP_1_LINEAR_SCORE",    
  "HcahpsLinearMeanValue_H_COMP_2_LINEAR_SCORE",    
  "HcahpsLinearMeanValue_H_COMP_3_LINEAR_SCORE",    
  "HcahpsLinearMeanValue_H_COMP_5_LINEAR_SCORE",    
  "HcahpsLinearMeanValue_H_COMP_6_LINEAR_SCORE",    
  "HcahpsLinearMeanValue_H_COMP_7_LINEAR_SCORE",    
  "HcahpsLinearMeanValue_H_CLEAN_LINEAR_SCORE",     
  "HcahpsLinearMeanValue_H_QUIET_LINEAR_SCORE"
)

# Remove specified columns
HipKneeTest <- HipKneeTest %>% select(-all_of(columns_to_remove))
```

```{r}
# Print column names to verify
print("Remaining columns:")
print(colnames(HipKneeTest))
```

#### Reassess collinearity with heatmap and correlation matrix
```{r, fig.width=14, fig.height=15}
# Compute correlation matrix
cor_matrix <- cor(HipKneeTest %>% select_if(is.numeric), use = "pairwise.complete.obs")

# Melt the correlation matrix into a long format
cor_melted <- melt(cor_matrix)

# Plot heatmap
ggplot(cor_melted, aes(x = Var1, y = Var2, fill = value)) +
  geom_tile() +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                       midpoint = 0, limit = c(-1, 1), name = "Correlation") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(title = "Figure 5. Correlation Heatmap of Numeric Variables")

# Convert correlation matrix to df
cor_table <- as.data.frame(cor_matrix)

# Add variable names as a column
cor_table$Variable <- rownames(cor_table)

# Reorder columns
cor_table <- cor_table %>%
  select(Variable, everything())

# Print table
cor_table %>%
  kable(caption = "Table 8. Correlation Coefficients Table") %>%
  kable_styling(bootstrap_options = c("hover", "striped", "responsive"))
```

### Imputation and Handling of Missing Values

```{r}
# Change - to _ in HIP-KNEE
colnames(HipKneeTest) <- gsub("-", "_", colnames(HipKneeTest))

# Remove all NA values in target variable "PredictedReadmissionRate_HIP_KNEE"
HipKneeTest <- HipKneeTest %>% filter(!is.na(PredictedReadmissionRate_HIP_KNEE))

# Remove all NA values in the "State", "StateCode", and "FacilityName" columns
HipKneeTest <- HipKneeTest %>% drop_na(State, StateCode, FacilityName)


# Print number of remaining variables and observations
dimensions <- dim(HipKneeTest)
cat("Number of variables:", dimensions[2], "\n")
cat("Number of observations:", dimensions[1], "\n")
```

```{r}
# Calculate missing values
missing_values_summary <- HipKneeTest %>%
  summarise(across(everything(), ~ sum(is.na(.)))) %>%
  pivot_longer(cols = everything(), names_to = "Variable", values_to = "Missing_Count") %>%
  mutate(Missing_Percentage = (Missing_Count / nrow(HipKneeTest)) * 100)

# Print table
missing_values_summary %>%
  kable(caption = "Table 7. Missing Values Summary") %>%
  kable_styling(bootstrap_options = c("hover", "striped", "responsive"))
```

#### Impute variables with low percentage missingness (<5%) by the median for numeric variables and mode for categorical variables
```{r}
# Calculate median for columns with <5% missing values
numeric_vars_low_missing <- c("HcahpsLinearMeanValue_H_HSP_RATING_LINEAR_SCORE", "EDV", "HCP_COVID_19", "IMM_3", "OP_18b", "SAFE_USE_OF_OPIOIDS", "Score_COMP_HIP_KNEE", "Score_PSI_03", "Score_PSI_06", "Score_PSI_08", "Score_PSI_09", "Score_PSI_10", "Score_PSI_11", "Score_PSI_12", "Score_PSI_13", "Score_PSI_14", "Score_PSI_15", "Payment_PAYM_90_HIP_KNEE")

for (var in numeric_vars_low_missing) {
  HipKneeTest[[var]][is.na(HipKneeTest[[var]])] <- median(HipKneeTest[[var]], na.rm = TRUE)
}
```

#### Impute high percentage missingness variables (>5%) using KNN
```{r}
# Select high missingness variables for KNN imputation
vars_for_knn <- c("VTE_1", "Score_MORT_30_AMI", "Score_MORT_30_COPD", "Score_MORT_30_HF", "Score_MORT_30_PN", "Score_MORT_30_STK", "Score_PSI_04", "OP_29")

# Perform KNN imputation
HipKneeTest_knn <- kNN(HipKneeTest, variable = vars_for_knn, k = 5)

# Remove columns created by the KNN function
HipKneeTest_knn <- HipKneeTest_knn %>% select(-ends_with("_imp"))

# Update HipKneeTrain with imputed values
HipKneeTest[vars_for_knn] <- HipKneeTest_knn[vars_for_knn]
```

```{r}
# Calculate missing values
missing_values_summary <- HipKneeTest %>%
  summarise(across(everything(), ~ sum(is.na(.)))) %>%
  pivot_longer(cols = everything(), names_to = "Variable", values_to = "Missing_Count") %>%
  mutate(Missing_Percentage = (Missing_Count / nrow(HipKneeTest)) * 100)

# Print table
missing_values_summary %>%
  kable(caption = "Table 7. Missing Values Summary") %>%
  kable_styling(bootstrap_options = c("hover", "striped", "responsive"))
```

#### Feature Engineer Mortality Data 
```{r}
# Average death rates amongst mortality variables and create new column "Score_Ovr_MORT"
HipKneeTest$Score_Ovr_MORT <- rowMeans(HipKneeTest[, c("Score_MORT_30_AMI", 
                                                         "Score_MORT_30_COPD", 
                                                         "Score_MORT_30_HF", 
                                                         "Score_MORT_30_PN", 
                                                         "Score_MORT_30_STK")], 
                                                          na.rm = TRUE)

# Remove old mortality columns
HipKneeTest <- HipKneeTest[, !(names(HipKneeTest) %in% c("Score_MORT_30_AMI", 
                                                            "Score_MORT_30_COPD",
                                                            "Score_MORT_30_HF", 
                                                            "Score_MORT_30_PN", 
                                                            "Score_MORT_30_STK"))]

```

#### Reassess heatmap with engineered mortality data
```{r, fig.width=14, fig.height=15}
# Compute correlation matrix
cor_matrix <- cor(HipKneeTest %>% select_if(is.numeric), use = "pairwise.complete.obs")

# Melt the correlation matrix into a long format
cor_melted <- melt(cor_matrix)

# Plot heatmap
ggplot(cor_melted, aes(x = Var1, y = Var2, fill = value)) +
  geom_tile() +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                       midpoint = 0, limit = c(-1, 1), name = "Correlation") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(title = "Figure 5. Correlation Heatmap of Numeric Variables")
```

#### Save the data for future ease of use
```{r}
save(HipKneeTest, file = "HipKneeTest.RData")
```

## Descriptive Statistics
```{r}
# Create a summary table of descriptive statistics
descr_stats <- describe(HipKneeTrain)
# Remove the rows with Facility ID, State and State code, and facility name
descr_stats <- descr_stats %>% filter(vars != c(1, 23, 24, 26))
# Remove columns 1, 2, 5, and 6
descr_stats <- descr_stats[, -c(1, 2, 5, 6)]

# Create a table with kable
kable(descr_stats, format = "html", caption = "Descriptive Statistics for All Numeric Variables in Final Dataset") %>%
  kable_styling(
    bootstrap_options = c("hover", "striped", "responsive")
  ) %>%
  column_spec(1, bold = TRUE) %>%
  column_spec(2, width = "5em") %>%
  row_spec(0, bold = TRUE, background = "#f2f2f2")

# Select numeric columns
numeric_columns <- HipKneeTrain %>% select_if(is.numeric)

# Melt the data for easier plotting with ggplot2
numeric_melted <- melt(numeric_columns)

# Create histograms
ggplot(numeric_melted, aes(x = value)) +
  geom_histogram(bins = 30, fill = "blue", color = "black") +
  facet_wrap(~variable, scales = "free_x") +
  theme_minimal() +
  labs(title = "Histograms of Numeric Variables", x = "Value", y = "Frequency")
```

# Appendix 3: Segmentation Analysis Code

## k-means Clustering (SE)
```{r}
# Select numeric columns for clustering
numeric_columns <- HipKneeTrain %>% select_if(is.numeric)

# Standardize features
X_scaled <- scale(numeric_columns)

# Determine optimal number of clusters using elbow plot
set.seed(123)
elbow_plot <- fviz_nbclust(X_scaled, kmeans, method = "wss", k.max = 10) +
  labs(title = "Elbow Plot for Optimal k")

print(elbow_plot)

# Optimal K = 3
optimal_k <- 3
kmeans_result <- kmeans(X_scaled, centers = optimal_k, nstart = 25)

# Create a new df for K-Means Clustering results
HipKneeTrain_K_Means <- HipKneeTrain %>%
  mutate(Cluster = as.factor(kmeans_result$cluster))

# Visualize clusters
fviz_cluster(kmeans_result, data = X_scaled,
             ellipse.type = "convex",
             palette = "jco",
             ggtheme = theme_minimal())

# Cluster characteristics
cluster_summary <- HipKneeTrain_K_Means %>%
  group_by(Cluster) %>%
  summarise_if(is.numeric, mean, na.rm = TRUE)

print(cluster_summary)

# Visualize feature distributions across clusters
features_to_plot <- c("PredictedReadmissionRate_HIP_KNEE", "HcahpsLinearMeanValue_H_HSP_RATING_LINEAR_SCORE", "Score_COMP_HIP_KNEE", "SAFE_USE_OF_OPIOIDS")

for (feature in features_to_plot) {
  p <- ggplot(HipKneeTrain_K_Means, aes(x = Cluster, y = .data[[feature]], fill = Cluster)) +
    geom_boxplot() +
    theme_minimal() +
    labs(title = paste("Distribution of", feature, "across clusters"))
  print(p)
}
```

## Hierarchical Clustering (SE)
```{r}
# Perform PCA
pca_result <- prcomp(X_scaled, center = TRUE, scale. = TRUE)

# Visualize variance
fviz_eig(pca_result, addlabels = TRUE)

# Factor map
fviz_pca_var(pca_result, col.var = "contrib",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE)

# PC scores, three components
pca_scores <- as.data.frame(pca_result$x[, 1:3])

# Store PCA results in a new dataframe
HipKneeTrain_PCA <- HipKneeTrain %>%
  select_if(is.numeric) %>%
  bind_cols(pca_scores)

# Hierarchical Clustering

# Compute distance matrix
dist_matrix <- dist(X_scaled, method = "euclidean")

# Perform hierarchical clustering
hc_result <- hclust(dist_matrix, method = "ward.D2")

# Compute WCSS for different number of clusters
wcss <- sapply(1:10, function(k) {
  clusters <- cutree(hc_result, k)
  cluster_data <- scale(X_scaled)
  tot.withinss <- sum(sapply(unique(clusters), function(c) {
    sum(dist(cluster_data[clusters == c, , drop = FALSE])^2)
  }))
  return(tot.withinss)
})

# Plot WCSS
plot(1:10, wcss, type = "b", xlab = "Number of Clusters", ylab = "WCSS")

# Create clusters with optimal number of clusters from WCSS plot
k <- 3
hc_clusters <- cutree(hc_result, k = k)

# Store hierarchical clustering results in a new dataframe
HipKneeTrain_HC <- HipKneeTrain %>%
  mutate(HC_Cluster = as.factor(hc_clusters))

# Visualize clusters using first three PCs
pca_plot_data <- cbind(pca_scores[, 1:3], Cluster = hc_clusters)
fviz_cluster(list(data = pca_plot_data, cluster = hc_clusters),
             ellipse.type = "convex",
             palette = "jco",
             ggtheme = theme_minimal(),
             main = "Hierarchical Clustering Results (PCA)")

# Analyze cluster characteristics
hc_cluster_summary <- HipKneeTrain_HC %>%
  group_by(HC_Cluster) %>%
  summarise_if(is.numeric, mean, na.rm = TRUE)

print(hc_cluster_summary)

# Visualize feature distributions across clusters
features_to_plot <- c("PredictedReadmissionRate_HIP_KNEE", "HcahpsLinearMeanValue_H_HSP_RATING_LINEAR_SCORE", "Score_COMP_HIP_KNEE", "SAFE_USE_OF_OPIOIDS")

for (feature in features_to_plot) {
  p <- ggplot(HipKneeTrain_HC, aes_string(x = "HC_Cluster", y = feature, fill = "HC_Cluster")) +
    geom_boxplot() +
    theme_minimal() +
    labs(title = paste("Distribution of", feature, "across Hierarchical Clusters"))
  print(p)
}
```
> This is a preliminary segmentation analysis and we would go forth and tighten/tidy this up some more. However, just initial impression, I'm not sure clustering is entirely beneficial with our dataset. What are your thoughts on our preliminary segmentation analysis? Any ideas in which we could improve our clustering to perhaps be more meaningful?

# Appendix 4: Initial Model Code
## Random Forest
### Creating the model
```{r}
# Remove unwanted columns from the dataset
HipKneeTrain_RF <- HipKneeTrain %>%
  select(-State, -FacilityName, -FacilityId)

# Define mtry parameter grid
grid <- expand.grid(
  mtry = c(2, 4, 6, 8)
)

# Define CV
train_control <- trainControl(
  method = "cv",         
  number = 7,           
  verboseIter = TRUE     
)

# Set seed 
set.seed(123)

# Train the Random Forest model with grid search
rf_grid_search <- train(
  PredictedReadmissionRate_HIP_KNEE ~ .,   
  data = HipKneeTrain_RF,                    
  method = "rf",                          
  trControl = train_control,              
  tuneGrid = grid,                       
  importance = TRUE,                     
  ntree = 100                         
)

# Best parameters
best_params <- rf_grid_search$bestTune
print(best_params)

# Extract feature importances
best_rf_model <- rf_grid_search$finalModel
feature_importances <- importance(best_rf_model)

# Convert feature importances to a df
feature_importances_df <- as.data.frame(feature_importances)
feature_importances_df$Feature <- rownames(feature_importances_df)

# Sort importances by %IncMSE
sorted_by_inc_mse <- feature_importances_df %>%
  arrange(desc(`%IncMSE`))

# Sort importances by IncNodePurity
sorted_by_inc_node_purity <- feature_importances_df %>%
  arrange(desc(IncNodePurity))

# Print importances
cat("Feature Importances by %IncMSE:\n")
print(sorted_by_inc_mse)

cat("\nFeature Importances by IncNodePurity:\n")
print(sorted_by_inc_node_purity)
```

### Assessing Random Forest Performance
```{r}
# Remove columns from the test set to match train set
HipKneeTest_RF <- HipKneeTest %>%
  select(-State, -FacilityName, -FacilityId)

# Make predictions on test set
rf_predictions <- predict(rf_grid_search, newdata = HipKneeTest_RF)

# Actual values
actual_values <- HipKneeTest$PredictedReadmissionRate_HIP_KNEE

# Calculate RMSE
mse <- mean((rf_predictions - actual_values)^2)
rmse <- sqrt(mse)

# Calculate R-squared
ss_total <- sum((actual_values - mean(actual_values))^2)
ss_residual <- sum((rf_predictions - actual_values)^2)
r_squared <- 1 - (ss_residual / ss_total)

# Print RMSE and R-squared
cat("RMSE on test set:\n")
print(rmse)

cat("\nR-squared on test set:\n")
print(r_squared)
```

### Testing assumptions
```{r}
# Calculate residuals
residuals_rf <- actual_values - rf_predictions

# Residuals vs Fitted Values plot
ggplot(data = NULL, aes(x = rf_predictions, y = residuals_rf)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "loess", se = FALSE, color = "blue") +
  labs(title = "Residuals vs Fitted Values",
       x = "Fitted Values",
       y = "Residuals") +
  theme_minimal()

# Histogram of residuals
ggplot(data = NULL, aes(x = residuals_rf)) +
  geom_histogram(binwidth = 0.1, fill = "blue", alpha = 0.7, boundary = 0) +
  labs(title = "Histogram of Residuals",
       x = "Residuals",
       y = "Frequency") +
  theme_minimal()

# QQ plot of residuals
qqnorm(residuals_rf, main = "QQ Plot of Residuals")
qqline(residuals_rf, col = "red")

# Perform Durbin-Watson test for autocorrelation in residuals
dw_test_result <- dwtest(lm(residuals_rf ~ rf_predictions))
print(dw_test_result)
```


